{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('cornell-moviedialog-corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conv_lines = open('cornell-moviedialog-corpus/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sample of the data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\",\n",
       " 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow',\n",
       " \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\",\n",
       " 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No',\n",
       " 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?',\n",
       " 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the conversations for POC 1 from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each line's id with its text\n",
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        if _line[2] == 'm159' :\n",
    "            id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the conversations' lines' ids.\n",
    "convs = []\n",
    "for line in conv_lines[:-1]:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) >= 4:\n",
    "        if _line[2] == 'm159':\n",
    "            _line = _line[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "            convs.append(_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L441948 Raise the sails.\n",
      "L441949 The wind is quarter from astern ... by the time we're underway, we'll never catch them.\n",
      "L441950 We need only to come about, to put them in range of the long nines.\n"
     ]
    }
   ],
   "source": [
    "for k in convs[100]:\n",
    "    print (k, id2line[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sort the sentences into questions (inputs) and answers (targets)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for conv in convs:\n",
    "    for i in range(len(conv)-1):\n",
    "        questions.append(id2line[conv[i]])\n",
    "        answers.append(id2line[conv[i+1]])\n",
    "        \n",
    "# Compare lengths of questions and answers\n",
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Handling Dataset size issue\n",
    "\n",
    "Since this dataset is very small in size, we append the dialogs from the 4 other POC movies to this.\n",
    "The scripts for these movies are publicly available from multiple sources. We scrape the movie scripts into text files and the extract question answer pairs from them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 camelliadebnath  staff   76547 May 22 12:28 POC1.txt\r\n",
      "-rw-r--r--@ 1 camelliadebnath  staff   97258 May 21 16:49 POC2.txt\r\n",
      "-rw-r--r--@ 1 camelliadebnath  staff   79823 May 22 12:42 POC3.txt\r\n",
      "-rw-r--r--@ 1 camelliadebnath  staff  111840 May 22 12:46 POC4.txt\r\n",
      "-rw-r--r--@ 1 camelliadebnath  staff  120175 May 22 12:46 POC5.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls -al POC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processScript(scriptFile, movie)->pd.DataFrame:\n",
    "    lines = scriptFile.readlines()\n",
    "    dialogs = [re.sub(r'[\\(\\[].*?[\\)\\]]', '', x) for x in lines]\n",
    "    dialog_df = []\n",
    "    scene = 0\n",
    "    for l in dialogs:\n",
    "        row = l.split(':')\n",
    "        if len(row)>= 2:\n",
    "            if row[0].startswith('SCENE') or row[0].startswith('Scene'):\n",
    "                m = re.search(r'\\d+$', row[0])\n",
    "                scene = int(m.group())\n",
    "            else:\n",
    "                dialog_df.append({'Movie':movie, 'Scene':scene, 'Character':row[0],'Dialog':row[1].rstrip()})\n",
    "    dialog_df = pd.DataFrame(dialog_df)\n",
    "    return dialog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(826, 4)\n",
      "(2761, 4)\n"
     ]
    }
   ],
   "source": [
    "f2 = open(\"POC2.txt\", \"r\")\n",
    "poc2 = processScript(f2, 2)\n",
    "\n",
    "f3 = open(\"POC3.txt\", \"r\")\n",
    "poc3 = processScript(f3, 3)\n",
    "\n",
    "f4 = open(\"POC4.txt\", \"r\")\n",
    "poc4 = processScript(f4, 4)\n",
    "\n",
    "f5 = open(\"POC5.txt\", \"r\")\n",
    "poc5 = processScript(f5, 5)\n",
    "\n",
    "print(poc2.shape)\n",
    "poc = poc2.append(poc3).append(poc4).append(poc5)\n",
    "\n",
    "print(poc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie                                     2\n",
       "Scene                                     1\n",
       "Character                         Elizabeth\n",
       "Dialog         Will. Why is this happening?\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poc.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3074\n",
      "3074\n"
     ]
    }
   ],
   "source": [
    "for i in range(poc.shape[0]-1):\n",
    "    questions.append(poc.iloc[i].Dialog)\n",
    "    answers.append(poc.iloc[i+1].Dialog)\n",
    "        \n",
    "# Compare lengths of questions and answers\n",
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Text Cleaning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
    "#     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "clean_answers = []    \n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "18.0\n",
      "22.0\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# Find the length of sentences (not using nltk due to processing speed)\n",
    "lengths = []\n",
    "# lengths.append([len(nltk.word_tokenize(sent)) for sent in clean_questions]) #nltk approach\n",
    "for question in clean_questions:\n",
    "    lengths.append(len(question.split()))\n",
    "for answer in clean_answers:\n",
    "    lengths.append(len(answer.split()))\n",
    "# Create a dataframe so that the values can be inspected\n",
    "lengths = pd.DataFrame(lengths, columns=['counts'])\n",
    "print(np.percentile(lengths, 80))\n",
    "print(np.percentile(lengths, 85))\n",
    "print(np.percentile(lengths, 90))\n",
    "print(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408\n",
      "2408\n"
     ]
    }
   ],
   "source": [
    "# Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
    "min_line_length = 1\n",
    "max_line_length = 20\n",
    "\n",
    "# Filter out the questions that are too short/long\n",
    "short_questions_temp = []\n",
    "short_answers_temp = []\n",
    "\n",
    "for i, question in enumerate(clean_questions):\n",
    "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
    "        short_questions_temp.append(question)\n",
    "        short_answers_temp.append(clean_answers[i])\n",
    "\n",
    "# Filter out the answers that are too short/long\n",
    "short_questions = []\n",
    "short_answers = []\n",
    "\n",
    "for i, answer in enumerate(short_answers_temp):\n",
    "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
    "        short_answers.append(answer)\n",
    "        short_questions.append(short_questions_temp[i])\n",
    "        \n",
    "print(len(short_questions))\n",
    "print(len(short_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample question-answer pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone?\n",
      "if we had something sharp, i could pick that lock.\n",
      "\n",
      "if we had something sharp, i could pick that lock.\n",
      "you are not going to find anything that sharp here.\n",
      "\n",
      "you are not going to find anything that sharp here.\n",
      "keep still, you bilge rat. captain!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = np.random.randint(1,len(short_questions))\n",
    "\n",
    "for i in range(r, r+3):\n",
    "    print(short_questions[i])\n",
    "    print(short_answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing number of samples\n",
    "num_samples = 2200  # Number of samples to train on.\n",
    "short_questions = short_questions[:num_samples]\n",
    "short_answers = short_answers[:num_samples]\n",
    "#tokenizing the qns and answers\n",
    "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
    "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size 1760\n",
      "validation size 440\n"
     ]
    }
   ],
   "source": [
    "#train-validation split\n",
    "data_size = len(short_questions_tok)\n",
    "\n",
    "# We will use the first 0-80th %-tile (80%) of data for the training\n",
    "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
    "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
    "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
    "\n",
    "# We will use the remaining for validation\n",
    "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
    "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
    "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
    "\n",
    "print('training size', len(training_input))\n",
    "print('validation size', len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word en/decoding dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for the frequency of the vocabulary\n",
    "# Create \n",
    "vocab = {}\n",
    "for question in short_questions_tok:\n",
    "    for word in question:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "\n",
    "for answer in short_answers_tok:\n",
    "    for word in answer:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of total vocab: 2682\n",
      "Size of vocab we will use: 796\n"
     ]
    }
   ],
   "source": [
    "# Remove rare words from the vocabulary.\n",
    "# We will aim to replace fewer than 5% of words with <UNK>\n",
    "# You will see this ratio soon.\n",
    "threshold = 5\n",
    "count = 0\n",
    "for k,v in vocab.items():\n",
    "    if v >= threshold:\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "print(\"Size of total vocab:\", len(vocab))\n",
    "print(\"Size of vocab we will use:\", count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of vocab used: 798\n"
     ]
    }
   ],
   "source": [
    "#we will create dictionaries to provide a unique integer for each word.\n",
    "WORD_CODE_START = 1\n",
    "WORD_CODE_PADDING = 0\n",
    "\n",
    "\n",
    "word_num  = 2 #number 1 is left for WORD_CODE_START for model decoder later\n",
    "encoding = {}\n",
    "decoding = {1: 'START'}\n",
    "for word, count in vocab.items():\n",
    "    if count >= threshold: #get vocabularies that appear above threshold count\n",
    "        encoding[word] = word_num \n",
    "        decoding[word_num ] = word\n",
    "        word_num += 1\n",
    "\n",
    "print(\"No. of vocab used:\", word_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include unknown token for words not in dictionary\n",
    "decoding[len(encoding)+2] = '<UNK>'\n",
    "encoding['<UNK>'] = len(encoding)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = word_num+1\n",
    "dict_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(encoding, data, vector_size=20):\n",
    "    \"\"\"\n",
    "    :param encoding: encoding dict built by build_word_encoding()\n",
    "    :param data: list of strings\n",
    "    :param vector_size: size of each encoded vector\n",
    "    \"\"\"\n",
    "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(min(len(data[i]), vector_size)):\n",
    "            try:\n",
    "                transformed_data[i][j] = encoding[data[i][j]]\n",
    "            except:\n",
    "                transformed_data[i][j] = encoding['<UNK>']\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_training_input (1760, 20)\n",
      "encoded_training_output (1760, 20)\n"
     ]
    }
   ],
   "source": [
    "#encoding training set\n",
    "encoded_training_input = transform(\n",
    "    encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = transform(\n",
    "    encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_training_input', encoded_training_input.shape)\n",
    "print('encoded_training_output', encoded_training_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_validation_input (440, 20)\n",
      "encoded_validation_output (440, 20)\n"
     ]
    }
   ],
   "source": [
    "#encoding validation set\n",
    "encoded_validation_input = transform(\n",
    "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = transform(\n",
    "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_validation_input', encoded_validation_input.shape)\n",
    "print('encoded_validation_output', encoded_validation_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm_1/transpose_2:0\", shape=(None, 20, 512), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice:0\", shape=(None, 512), dtype=float32)\n",
      "decoder Tensor(\"lstm_2/transpose_2:0\", shape=(None, 20, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)\n",
    "\n",
    "# For the plain Sequence-to-Sequence, we produced the output from directly from decoder\n",
    "# output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"attention/truediv:0\", shape=(None, 20, 20), dtype=float32)\n",
      "context Tensor(\"dot_2/MatMul:0\", shape=(None, 20, 512), dtype=float32)\n",
      "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(None, 20, 1024), dtype=float32)\n",
      "output Tensor(\"time_distributed_2/Reshape_1:0\", shape=(None, 20, 799), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "attention = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "# Has another weight + tanh layer as described in equation (5) of the paper\n",
    "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
    "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
    "print('output', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 128)      102272      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 128)      102272      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 20, 512)      1312768     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 512)      1312768     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 20, 20)       0           lstm_2[0][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 20, 20)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 20, 512)      0           attention[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 1024)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 20, 512)      524800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 20, 799)      409887      time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,764,767\n",
      "Trainable params: 3,764,767\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_encoder_input = encoded_training_input\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = WORD_CODE_START\n",
    "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = WORD_CODE_START\n",
    "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1760 samples, validate on 440 samples\n",
      "Epoch 1/100\n",
      "1760/1760 [==============================] - 29s 17ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 2/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 3/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 4/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 5/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 6/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 7/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 8/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 9/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 10/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 11/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 13/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 14/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 15/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 16/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 17/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 18/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 19/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 20/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 21/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 22/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 23/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 24/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 25/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 26/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 27/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 28/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 29/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 30/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 31/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 32/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 33/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 34/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 35/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 37/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 38/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 39/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 40/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 41/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 42/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 43/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 44/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 45/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 48/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 49/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 50/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 51/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 52/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 53/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 54/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 55/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 56/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 57/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 58/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 59/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 60/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 9.7355e-04 - val_loss: 0.0046\n",
      "Epoch 61/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 9.1628e-04 - val_loss: 0.0047\n",
      "Epoch 62/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 8.6083e-04 - val_loss: 0.0047\n",
      "Epoch 63/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 8.0714e-04 - val_loss: 0.0047\n",
      "Epoch 64/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 7.5483e-04 - val_loss: 0.0048\n",
      "Epoch 65/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 7.1407e-04 - val_loss: 0.0048\n",
      "Epoch 66/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 6.6718e-04 - val_loss: 0.0049\n",
      "Epoch 67/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 6.2172e-04 - val_loss: 0.0049\n",
      "Epoch 68/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 5.8720e-04 - val_loss: 0.0050\n",
      "Epoch 69/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 5.5553e-04 - val_loss: 0.0050\n",
      "Epoch 70/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 5.3310e-04 - val_loss: 0.0051\n",
      "Epoch 71/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 5.1314e-04 - val_loss: 0.0051\n",
      "Epoch 72/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 4.9398e-04 - val_loss: 0.0052\n",
      "Epoch 73/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 4.6679e-04 - val_loss: 0.0052\n",
      "Epoch 74/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 4.3286e-04 - val_loss: 0.0053\n",
      "Epoch 75/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 4.0618e-04 - val_loss: 0.0053\n",
      "Epoch 76/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 3.7835e-04 - val_loss: 0.0053\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760/1760 [==============================] - 23s 13ms/step - loss: 3.5008e-04 - val_loss: 0.0054\n",
      "Epoch 78/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 3.3134e-04 - val_loss: 0.0054\n",
      "Epoch 79/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 3.1131e-04 - val_loss: 0.0054\n",
      "Epoch 80/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 2.9677e-04 - val_loss: 0.0055\n",
      "Epoch 81/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 2.8848e-04 - val_loss: 0.0055\n",
      "Epoch 82/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 2.6584e-04 - val_loss: 0.0055\n",
      "Epoch 83/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 2.5233e-04 - val_loss: 0.0056\n",
      "Epoch 84/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 2.3122e-04 - val_loss: 0.0056\n",
      "Epoch 85/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 2.0623e-04 - val_loss: 0.0056\n",
      "Epoch 86/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.9263e-04 - val_loss: 0.0057\n",
      "Epoch 87/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.8208e-04 - val_loss: 0.0057\n",
      "Epoch 88/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.6327e-04 - val_loss: 0.0057\n",
      "Epoch 89/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.4877e-04 - val_loss: 0.0058\n",
      "Epoch 90/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.3608e-04 - val_loss: 0.0058\n",
      "Epoch 91/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 1.2426e-04 - val_loss: 0.0058\n",
      "Epoch 92/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.1582e-04 - val_loss: 0.0059\n",
      "Epoch 93/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.0797e-04 - val_loss: 0.0059\n",
      "Epoch 94/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.1747e-04 - val_loss: 0.0060\n",
      "Epoch 95/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.2009e-04 - val_loss: 0.0059\n",
      "Epoch 96/100\n",
      "1760/1760 [==============================] - 23s 13ms/step - loss: 1.1645e-04 - val_loss: 0.0059\n",
      "Epoch 97/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.0877e-04 - val_loss: 0.0059\n",
      "Epoch 98/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.1504e-04 - val_loss: 0.0059\n",
      "Epoch 99/100\n",
      "1760/1760 [==============================] - 22s 13ms/step - loss: 1.7724e-04 - val_loss: 0.0059\n",
      "Epoch 100/100\n",
      "1760/1760 [==============================] - 22s 12ms/step - loss: 3.1174e-04 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/network.py:896: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice:0' shape=(None, 512) dtype=float32>, <tf.Tensor 'strided_slice:0' shape=(None, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          #validation_split=0.05,\n",
    "          batch_size=64, epochs=100)\n",
    "\n",
    "model.save('model_attention.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(raw_input):\n",
    "    clean_input = clean_text(raw_input)\n",
    "    input_tok = [nltk.word_tokenize(clean_input)]\n",
    "    input_tok = [input_tok[0][::-1]]  #reverseing input seq\n",
    "    encoder_input = transform(encoding, input_tok, 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = WORD_CODE_START\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return output\n",
    "\n",
    "def decode(decoding, vector):\n",
    "    \"\"\"\n",
    "    :param decoding: decoding dict built by word encoding\n",
    "    :param vector: an encoded vector\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in vector:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += ' '\n",
    "        text += decoding[i]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: tell me the weather\n",
      "A:  no .\n",
      "\n",
      "Q: I need help\n",
      "A:  you <UNK> me , <UNK> me , hurry !\n",
      "\n",
      "Q: can you help me?\n",
      "A:  no ... you are be my father .\n",
      "\n",
      "Q: where am I?\n",
      "A:  you are beautiful .\n",
      "\n",
      "Q: who are you?\n",
      "A:  no .\n",
      "\n",
      "Q: where is the ship?\n",
      "A:  and there were a very <UNK> . without his face familiar to <UNK> .\n",
      "\n",
      "Q: who are you?\n",
      "A:  no .\n",
      "\n",
      "Q: who is a good boy?\n",
      "A:  no .\n",
      "\n",
      "Q: Am I a good boy?\n",
      "A:  ah , that is a <UNK> and <UNK> <UNK> ... in <UNK> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\"tell me the weather\", \"I need help\", \"can you help me?\", \"where am I?\",\n",
    "        \"who are you?\", \"where is the ship?\", \"who are you?\", \"who is a good boy?\",\n",
    "        \"Am I a good boy?\"]\n",
    "\n",
    "for text in texts:\n",
    "    output = prediction(text)\n",
    "    print ('Q:', text)\n",
    "    print ('A:', decode(decoding, output[0]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
