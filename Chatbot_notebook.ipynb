{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1045</th>\n",
       "      <th>They do not! Splice the mainbrace!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to! Cleave him to the brisket!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so. Avast ye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay? Arrr! Dead men tell no tales.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go. Thar she blows!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L924</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   L1045       They do not! Splice the mainbrace!\n",
       "0  L1044   They do to! Cleave him to the brisket!\n",
       "1   L985                     I hope so. Avast ye!\n",
       "2   L984  She okay? Arrr! Dead men tell no tales.\n",
       "3   L925                Let's go. Thar she blows!\n",
       "4   L924                                      Wow"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pirate_convert = pd.read_csv('pirate_convert.csv')\n",
    "pirate_convert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304712"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pirate_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to! Cleave him to the brisket!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so. Avast ye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay? Arrr! Dead men tell no tales.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go. Thar she blows!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L924</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                   dialog\n",
       "0  L1044   They do to! Cleave him to the brisket!\n",
       "1   L985                     I hope so. Avast ye!\n",
       "2   L984  She okay? Arrr! Dead men tell no tales.\n",
       "3   L925                Let's go. Thar she blows!\n",
       "4   L924                                      Wow"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pirate_convert.columns=['id','dialog']\n",
    "pirate_convert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to! Cleave him to the brisket!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so. Avast ye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay? Arrr! Dead men tell no tales.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go. Thar she blows!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L924</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304708</th>\n",
       "      <td>L666370</td>\n",
       "      <td>I'm to pillage th' sikali with th' main column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304709</th>\n",
       "      <td>L666369</td>\n",
       "      <td>Your orders, mr vereker?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304710</th>\n",
       "      <td>L666257</td>\n",
       "      <td>Good ones, yes, mr vereker. Gentlemen who can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304711</th>\n",
       "      <td>L666256</td>\n",
       "      <td>Colonel durnford... William vereker. I hear ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304712</th>\n",
       "      <td>L1045</td>\n",
       "      <td>They do not! Splice the mainbrace!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304713 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                             dialog\n",
       "0         L1044             They do to! Cleave him to the brisket!\n",
       "1          L985                               I hope so. Avast ye!\n",
       "2          L984            She okay? Arrr! Dead men tell no tales.\n",
       "3          L925                          Let's go. Thar she blows!\n",
       "4          L924                                                Wow\n",
       "...         ...                                                ...\n",
       "304708  L666370  I'm to pillage th' sikali with th' main column...\n",
       "304709  L666369                           Your orders, mr vereker?\n",
       "304710  L666257  Good ones, yes, mr vereker. Gentlemen who can ...\n",
       "304711  L666256  Colonel durnford... William vereker. I hear ye...\n",
       "304712    L1045                 They do not! Splice the mainbrace!\n",
       "\n",
       "[304713 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pirate_convert.append({'id':'L1045','dialog':'They do not! Splice the mainbrace!'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('cornell-moviedialog-corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conv_lines = open('cornell-moviedialog-corpus/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sample of the data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the conversations for POC 1 from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each line's id with its text\n",
    "id2line = {}\n",
    "\n",
    "for i in range(pirate_convert.shape[0]):\n",
    "    id2line[pirate_convert.iloc[i][0]] = pirate_convert.iloc[i][1]\n",
    "    \n",
    "    \n",
    "    \n",
    "#for line in lines:\n",
    "#    _line = line.split(' +++$+++ ')\n",
    "#    if len(_line) == 5:\n",
    "#        if _line[2] == 'm159' :\n",
    "#            id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the conversations' lines' ids.\n",
    "convs = []\n",
    "for line in conv_lines[:-1]:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) >= 4:\n",
    "        _line = _line[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83097"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L404 She's not a... Blimey!\n",
      "L405 Lesbian? No. I found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.\n",
      "L406 So that's th' kind of guy she likes? Pretty ones?\n",
      "L407 Who knows? All i've ever heard her say be that she'd dip before dating a guy that smokes.\n"
     ]
    }
   ],
   "source": [
    "for k in convs[12]:\n",
    "    print (k, id2line[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sort the sentences into questions (inputs) and answers (targets)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221615\n",
      "221615\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for conv in convs:\n",
    "    for i in range(len(conv)-1):\n",
    "        if conv[i+1] != 'L1045':\n",
    "            questions.append(id2line[conv[i]])\n",
    "            answers.append(id2line[conv[i+1]])\n",
    "        \n",
    "# Compare lengths of questions and answers\n",
    "print(len(questions))\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Text Cleaning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
    "#     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "clean_questions = []\n",
    "clean_answers = []    \n",
    "\n",
    "for i in range(len(questions)):\n",
    "    if type(questions[i]) == str and type(answers[i]) == str:\n",
    "        clean_questions.append(clean_text(questions[i]))\n",
    "        clean_answers.append(clean_text(answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221281\n",
      "221281\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_questions))\n",
    "print(len(clean_answers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "21.0\n",
      "26.0\n",
      "35.0\n"
     ]
    }
   ],
   "source": [
    "# Find the length of sentences (not using nltk due to processing speed)\n",
    "lengths = []\n",
    "# lengths.append([len(nltk.word_tokenize(sent)) for sent in clean_questions]) #nltk approach\n",
    "for question in clean_questions:\n",
    "    lengths.append(len(question.split()))\n",
    "for answer in clean_answers:\n",
    "    lengths.append(len(answer.split()))\n",
    "# Create a dataframe so that the values can be inspected\n",
    "lengths = pd.DataFrame(lengths, columns=['counts'])\n",
    "print(np.percentile(lengths, 80))\n",
    "print(np.percentile(lengths, 85))\n",
    "print(np.percentile(lengths, 90))\n",
    "print(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157278\n",
      "157278\n"
     ]
    }
   ],
   "source": [
    "# Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
    "min_line_length = 1\n",
    "max_line_length = 20\n",
    "\n",
    "# Filter out the questions that are too short/long\n",
    "short_questions_temp = []\n",
    "short_answers_temp = []\n",
    "\n",
    "for i, question in enumerate(clean_questions):\n",
    "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
    "        short_questions_temp.append(question)\n",
    "        short_answers_temp.append(clean_answers[i])\n",
    "\n",
    "# Filter out the answers that are too short/long\n",
    "short_questions = []\n",
    "short_answers = []\n",
    "\n",
    "for i, answer in enumerate(short_answers_temp):\n",
    "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
    "        short_answers.append(answer)\n",
    "        short_questions.append(short_questions_temp[i])\n",
    "        \n",
    "print(len(short_questions))\n",
    "print(len(short_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample question-answer pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i came all th' way here for that? to walk th' lobby?\n",
      "yeah. and it might have even worked too.\n",
      "\n",
      "yeah. and it might have even worked too.\n",
      "let's do it again. blimey!\n",
      "\n",
      "ye believe they are shooting a nike ad down there? did i ever tell ye me nike story?\n",
      "i gotta get back to cushman.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = np.random.randint(1,len(short_questions))\n",
    "\n",
    "for i in range(r, r+3):\n",
    "    print(short_questions[i])\n",
    "    print(short_answers[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing number of samples\n",
    "num_samples = 30000  # Number of samples to train on.\n",
    "short_questions = short_questions[:num_samples]\n",
    "short_answers = short_answers[:num_samples]\n",
    "#tokenizing the qns and answers\n",
    "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
    "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(short_questions_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size 24000\n",
      "validation size 6000\n"
     ]
    }
   ],
   "source": [
    "#train-validation split\n",
    "data_size = len(short_questions_tok)\n",
    "\n",
    "# We will use the first 0-80th %-tile (80%) of data for the training\n",
    "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
    "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
    "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
    "\n",
    "# We will use the remaining for validation\n",
    "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
    "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
    "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
    "\n",
    "print('training size', len(training_input))\n",
    "print('validation size', len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word en/decoding dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for the frequency of the vocabulary\n",
    "# Create \n",
    "vocab = {}\n",
    "for question in short_questions_tok:\n",
    "    for word in question:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "\n",
    "for answer in short_answers_tok:\n",
    "    for word in answer:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of total vocab: 15213\n",
      "Size of vocab we will use: 2519\n"
     ]
    }
   ],
   "source": [
    "# Remove rare words from the vocabulary.\n",
    "# We will aim to replace fewer than 5% of words with <UNK>\n",
    "# You will see this ratio soon.\n",
    "threshold = 10\n",
    "count = 0\n",
    "for k,v in vocab.items():\n",
    "    if v >= threshold:\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "print(\"Size of total vocab:\", len(vocab))\n",
    "print(\"Size of vocab we will use:\", count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of vocab used: 2521\n"
     ]
    }
   ],
   "source": [
    "#we will create dictionaries to provide a unique integer for each word.\n",
    "WORD_CODE_START = 1\n",
    "WORD_CODE_PADDING = 0\n",
    "\n",
    "\n",
    "word_num  = 2 #number 1 is left for WORD_CODE_START for model decoder later\n",
    "encoding = {}\n",
    "decoding = {1: 'START'}\n",
    "for word, count in vocab.items():\n",
    "    if count >= threshold: #get vocabularies that appear above threshold count\n",
    "        encoding[word] = word_num \n",
    "        decoding[word_num ] = word\n",
    "        word_num += 1\n",
    "\n",
    "print(\"No. of vocab used:\", word_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include unknown token for words not in dictionary\n",
    "decoding[len(encoding)+2] = '<UNK>'\n",
    "encoding['<UNK>'] = len(encoding)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = word_num+1\n",
    "dict_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(encoding, data, vector_size=20):\n",
    "    \"\"\"\n",
    "    :param encoding: encoding dict built by build_word_encoding()\n",
    "    :param data: list of strings\n",
    "    :param vector_size: size of each encoded vector\n",
    "    \"\"\"\n",
    "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(min(len(data[i]), vector_size)):\n",
    "            try:\n",
    "                transformed_data[i][j] = encoding[data[i][j]]\n",
    "            except:\n",
    "                transformed_data[i][j] = encoding['<UNK>']\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_training_input (24000, 20)\n",
      "encoded_training_output (24000, 20)\n"
     ]
    }
   ],
   "source": [
    "#encoding training set\n",
    "encoded_training_input = transform(\n",
    "    encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = transform(\n",
    "    encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_training_input', encoded_training_input.shape)\n",
    "print('encoded_training_output', encoded_training_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_validation_input (6000, 20)\n",
      "encoded_validation_output (6000, 20)\n"
     ]
    }
   ],
   "source": [
    "#encoding validation set\n",
    "encoded_validation_input = transform(\n",
    "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = transform(\n",
    "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('encoded_validation_input', encoded_validation_input.shape)\n",
    "print('encoded_validation_output', encoded_validation_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm_1/transpose_2:0\", shape=(None, 20, 512), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice:0\", shape=(None, 512), dtype=float32)\n",
      "decoder Tensor(\"lstm_2/transpose_2:0\", shape=(None, 20, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)\n",
    "\n",
    "# For the plain Sequence-to-Sequence, we produced the output from directly from decoder\n",
    "# output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"attention/truediv:0\", shape=(None, 20, 20), dtype=float32)\n",
      "context Tensor(\"dot_2/MatMul:0\", shape=(None, 20, 512), dtype=float32)\n",
      "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(None, 20, 1024), dtype=float32)\n",
      "output Tensor(\"time_distributed_2/Reshape_1:0\", shape=(None, 20, 2522), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "attention = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "# Has another weight + tanh layer as described in equation (5) of the paper\n",
    "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
    "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
    "print('output', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 128)      322816      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 128)      322816      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 20, 512)      1312768     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 20, 512)      1312768     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 20, 20)       0           lstm_2[0][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 20, 20)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 20, 512)      0           attention[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 1024)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 20, 512)      524800      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 20, 2522)     1293786     time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 5,089,754\n",
      "Trainable params: 5,089,754\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_encoder_input = encoded_training_input\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = WORD_CODE_START\n",
    "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = WORD_CODE_START\n",
    "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "24000/24000 [==============================] - 393s 16ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 2/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "24000/24000 [==============================] - 393s 16ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 0.0010 - val_loss: 9.9031e-04\n",
      "Epoch 5/100\n",
      "24000/24000 [==============================] - 393s 16ms/step - loss: 9.8784e-04 - val_loss: 9.7107e-04\n",
      "Epoch 6/100\n",
      "24000/24000 [==============================] - 394s 16ms/step - loss: 9.6732e-04 - val_loss: 9.5471e-04\n",
      "Epoch 7/100\n",
      "24000/24000 [==============================] - 397s 17ms/step - loss: 9.5201e-04 - val_loss: 9.4777e-04\n",
      "Epoch 8/100\n",
      "24000/24000 [==============================] - 399s 17ms/step - loss: 9.3948e-04 - val_loss: 9.3933e-04\n",
      "Epoch 9/100\n",
      "24000/24000 [==============================] - 393s 16ms/step - loss: 9.2856e-04 - val_loss: 9.3409e-04\n",
      "Epoch 10/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 9.1922e-04 - val_loss: 9.3270e-04\n",
      "Epoch 11/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 9.1034e-04 - val_loss: 9.2720e-04\n",
      "Epoch 12/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 9.0207e-04 - val_loss: 9.2582e-04\n",
      "Epoch 13/100\n",
      "24000/24000 [==============================] - 389s 16ms/step - loss: 8.9380e-04 - val_loss: 9.2433e-04\n",
      "Epoch 14/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 8.8581e-04 - val_loss: 9.2297e-04\n",
      "Epoch 15/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 8.7738e-04 - val_loss: 9.2274e-04\n",
      "Epoch 16/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 8.6951e-04 - val_loss: 9.2370e-04\n",
      "Epoch 17/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 8.6132e-04 - val_loss: 9.2493e-04\n",
      "Epoch 18/100\n",
      "24000/24000 [==============================] - 392s 16ms/step - loss: 8.5232e-04 - val_loss: 9.2468e-04\n",
      "Epoch 19/100\n",
      "24000/24000 [==============================] - 392s 16ms/step - loss: 8.4355e-04 - val_loss: 9.2700e-04\n",
      "Epoch 20/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 8.3374e-04 - val_loss: 9.2860e-04\n",
      "Epoch 21/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 8.2380e-04 - val_loss: 9.3278e-04\n",
      "Epoch 22/100\n",
      "24000/24000 [==============================] - 392s 16ms/step - loss: 8.1324e-04 - val_loss: 9.3441e-04\n",
      "Epoch 23/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 8.0260e-04 - val_loss: 9.3845e-04\n",
      "Epoch 24/100\n",
      "24000/24000 [==============================] - 389s 16ms/step - loss: 7.9126e-04 - val_loss: 9.4300e-04\n",
      "Epoch 25/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 7.7948e-04 - val_loss: 9.4778e-04\n",
      "Epoch 26/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 7.6686e-04 - val_loss: 9.5532e-04\n",
      "Epoch 27/100\n",
      "24000/24000 [==============================] - 391s 16ms/step - loss: 7.5370e-04 - val_loss: 9.6032e-04\n",
      "Epoch 28/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 7.4028e-04 - val_loss: 9.7085e-04\n",
      "Epoch 29/100\n",
      "24000/24000 [==============================] - 389s 16ms/step - loss: 7.2671e-04 - val_loss: 9.7581e-04\n",
      "Epoch 30/100\n",
      "24000/24000 [==============================] - 389s 16ms/step - loss: 7.1307e-04 - val_loss: 9.8310e-04\n",
      "Epoch 31/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 6.9830e-04 - val_loss: 9.9323e-04\n",
      "Epoch 32/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 6.8351e-04 - val_loss: 0.0010\n",
      "Epoch 33/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 6.6886e-04 - val_loss: 0.0010\n",
      "Epoch 34/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 6.5399e-04 - val_loss: 0.0010\n",
      "Epoch 35/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 6.3892e-04 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 6.2418e-04 - val_loss: 0.0010\n",
      "Epoch 37/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 6.0916e-04 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 5.9481e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 5.8040e-04 - val_loss: 0.0011\n",
      "Epoch 40/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 5.6623e-04 - val_loss: 0.0011\n",
      "Epoch 41/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 5.5206e-04 - val_loss: 0.0011\n",
      "Epoch 42/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 5.3854e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 5.2537e-04 - val_loss: 0.0011\n",
      "Epoch 44/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 5.1234e-04 - val_loss: 0.0012\n",
      "Epoch 45/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 4.9908e-04 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 4.8696e-04 - val_loss: 0.0012\n",
      "Epoch 47/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 4.7504e-04 - val_loss: 0.0012\n",
      "Epoch 48/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 4.6324e-04 - val_loss: 0.0012\n",
      "Epoch 49/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 4.5247e-04 - val_loss: 0.0012\n",
      "Epoch 50/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 4.4113e-04 - val_loss: 0.0012\n",
      "Epoch 51/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 4.3019e-04 - val_loss: 0.0012\n",
      "Epoch 52/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 4.2140e-04 - val_loss: 0.0013\n",
      "Epoch 53/100\n",
      "24000/24000 [==============================] - 389s 16ms/step - loss: 4.1148e-04 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 4.0307e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "24000/24000 [==============================] - 390s 16ms/step - loss: 3.9270e-04 - val_loss: 0.0013\n",
      "Epoch 56/100\n",
      "24000/24000 [==============================] - 392s 16ms/step - loss: 3.8447e-04 - val_loss: 0.0013\n",
      "Epoch 57/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 3.7588e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 3.6815e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 3.5976e-04 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 3.5483e-04 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 3.4915e-04 - val_loss: 0.0014\n",
      "Epoch 62/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 3.4056e-04 - val_loss: 0.0014\n",
      "Epoch 63/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 3.3202e-04 - val_loss: 0.0014\n",
      "Epoch 64/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 3.2711e-04 - val_loss: 0.0014\n",
      "Epoch 65/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 3.2266e-04 - val_loss: 0.0014\n",
      "Epoch 66/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 3.1651e-04 - val_loss: 0.0014\n",
      "Epoch 67/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 3.1113e-04 - val_loss: 0.0014\n",
      "Epoch 68/100\n",
      "24000/24000 [==============================] - 384s 16ms/step - loss: 3.0687e-04 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 3.0241e-04 - val_loss: 0.0014\n",
      "Epoch 70/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.9887e-04 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.9472e-04 - val_loss: 0.0015\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.9349e-04 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.8769e-04 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 2.8177e-04 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 2.7351e-04 - val_loss: 0.0015\n",
      "Epoch 76/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.6908e-04 - val_loss: 0.0015\n",
      "Epoch 77/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.6290e-04 - val_loss: 0.0015\n",
      "Epoch 78/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.6014e-04 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.6129e-04 - val_loss: 0.0015\n",
      "Epoch 80/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.6941e-04 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.6514e-04 - val_loss: 0.0015\n",
      "Epoch 82/100\n",
      "24000/24000 [==============================] - 384s 16ms/step - loss: 2.5262e-04 - val_loss: 0.0016\n",
      "Epoch 83/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.4097e-04 - val_loss: 0.0016\n",
      "Epoch 84/100\n",
      "24000/24000 [==============================] - 384s 16ms/step - loss: 2.3372e-04 - val_loss: 0.0016\n",
      "Epoch 85/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.3101e-04 - val_loss: 0.0016\n",
      "Epoch 86/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.3101e-04 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 2.4185e-04 - val_loss: 0.0016\n",
      "Epoch 88/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.4772e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "24000/24000 [==============================] - 387s 16ms/step - loss: 2.4238e-04 - val_loss: 0.0016\n",
      "Epoch 90/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.2508e-04 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.0947e-04 - val_loss: 0.0016\n",
      "Epoch 92/100\n",
      "24000/24000 [==============================] - 388s 16ms/step - loss: 1.9959e-04 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 1.9269e-04 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 1.9019e-04 - val_loss: 0.0017\n",
      "Epoch 95/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 1.9728e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 2.3276e-04 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.4115e-04 - val_loss: 0.0017\n",
      "Epoch 98/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 2.1136e-04 - val_loss: 0.0017\n",
      "Epoch 99/100\n",
      "24000/24000 [==============================] - 385s 16ms/step - loss: 1.9052e-04 - val_loss: 0.0017\n",
      "Epoch 100/100\n",
      "24000/24000 [==============================] - 386s 16ms/step - loss: 1.7354e-04 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/network.py:896: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice:0' shape=(None, 512) dtype=float32>, <tf.Tensor 'strided_slice:0' shape=(None, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          #validation_split=0.05,\n",
    "          batch_size=64, epochs=100)\n",
    "\n",
    "model.save('model_attention_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(raw_input):\n",
    "    clean_input = clean_text(raw_input)\n",
    "    input_tok = [nltk.word_tokenize(clean_input)]\n",
    "    input_tok = [input_tok[0][::-1]]  #reverseing input seq\n",
    "    encoder_input = transform(encoding, input_tok, 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = WORD_CODE_START\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return output\n",
    "\n",
    "def decode(decoding, vector):\n",
    "    \"\"\"\n",
    "    :param decoding: decoding dict built by word encoding\n",
    "    :param vector: an encoded vector\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in vector:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += ' '\n",
    "        text += decoding[i]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: oh, you have lost it, have not ya? dead men tell no tales.\n",
      "A:  i am here . thar she blows ! \n",
      "\n",
      "Q: were those flowers really for me, brad?\n",
      "A:  i do not want to pillage ye out with him . \n",
      "\n",
      "Q: rae... savvy? savvy?\n",
      "A:  i do not see why we got ta lie about it when ye and i know this ai not not \n",
      "\n",
      "Q: three, four years. avast ye!\n",
      "A:  that is all right now ? avast ye ! \n",
      "\n",
      "Q: where? savvy?\n",
      "A:  we are in th ' <UNK> of th ' <UNK> of <UNK> . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    seq_index = np.random.randint(1, len(short_questions))\n",
    "    output = prediction(short_questions[seq_index])\n",
    "    print ('Q:', short_questions[seq_index])\n",
    "    print ('A:', decode(decoding, output[0]),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who are you?\n",
      "A:  in th ' bedroom .\n",
      "\n",
      "Q: How are you doing?\n",
      "A:  not here 's than i get in !\n",
      "\n",
      "Q: What is your purpose?\n",
      "A:  whar be th ' emperor and th ' army , soldier ?\n",
      "\n",
      "Q: What can you do?\n",
      "A:  i think you are a freak . i think ye do this to <UNK> me . and i think think\n",
      "\n",
      "Q: I need help\n",
      "A:  i know . arrr !\n",
      "\n",
      "Q: Can you help me?\n",
      "A:  i will get him . splice the mainbrace !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Who are you?\", \"How are you doing?\", \"What is your purpose?\", \"What can you do?\", \"I need help\", \"Can you help me?\"]\n",
    "\n",
    "for text in texts:\n",
    "    output = prediction(text)\n",
    "    print ('Q:', text)\n",
    "    print ('A:', decode(decoding, output[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
